[2024-06-04 12:51:15,978] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcs_dag.transform_dataset_task scheduled__2024-06-03T00:00:00+00:00 [queued]>
[2024-06-04 12:51:15,995] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcs_dag.transform_dataset_task scheduled__2024-06-03T00:00:00+00:00 [queued]>
[2024-06-04 12:51:15,996] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-06-04 12:51:15,996] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-06-04 12:51:15,996] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-06-04 12:51:16,011] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): transform_dataset_task> on 2024-06-03 00:00:00+00:00
[2024-06-04 12:51:16,019] {standard_task_runner.py:52} INFO - Started process 15754 to run task
[2024-06-04 12:51:16,023] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'transform_dataset_task', 'scheduled__2024-06-03T00:00:00+00:00', '--job-id', '171', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion.py', '--cfg-path', '/tmp/tmpo2ap5uil', '--error-file', '/tmp/tmpaxjc92_g']
[2024-06-04 12:51:16,030] {standard_task_runner.py:77} INFO - Job 171: Subtask transform_dataset_task
[2024-06-04 12:51:16,113] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcs_dag.transform_dataset_task scheduled__2024-06-03T00:00:00+00:00 [running]> on host 7ae6972dd88f
[2024-06-04 12:51:16,204] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcs_dag
AIRFLOW_CTX_TASK_ID=transform_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2024-06-03T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-06-03T00:00:00+00:00
[2024-06-04 12:51:16,569] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion.py", line 45, in transform_dataset
    df = df[cols]
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2912, in __getitem__
    indexer = self.loc._get_listlike_indexer(key, axis=1, raise_missing=True)[1]
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/indexing.py", line 1254, in _get_listlike_indexer
    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/indexing.py", line 1298, in _validate_read_indexer
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['title', 'abstract', 'published_date', 'adx_keywords'], dtype='object')] are in the [columns]"
[2024-06-04 12:51:16,581] {taskinstance.py:1277} INFO - Marking task as UP_FOR_RETRY. dag_id=data_ingestion_gcs_dag, task_id=transform_dataset_task, execution_date=20240603T000000, start_date=20240604T125115, end_date=20240604T125116
[2024-06-04 12:51:16,593] {standard_task_runner.py:92} ERROR - Failed to execute job 171 for task transform_dataset_task
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/data_ingestion.py", line 45, in transform_dataset
    df = df[cols]
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/frame.py", line 2912, in __getitem__
    indexer = self.loc._get_listlike_indexer(key, axis=1, raise_missing=True)[1]
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/indexing.py", line 1254, in _get_listlike_indexer
    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/core/indexing.py", line 1298, in _validate_read_indexer
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['title', 'abstract', 'published_date', 'adx_keywords'], dtype='object')] are in the [columns]"
[2024-06-04 12:51:16,637] {local_task_job.py:154} INFO - Task exited with return code 1
[2024-06-04 12:51:16,667] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-04 13:00:17,888] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcs_dag.transform_dataset_task scheduled__2024-06-03T00:00:00+00:00 [queued]>
[2024-06-04 13:00:17,897] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcs_dag.transform_dataset_task scheduled__2024-06-03T00:00:00+00:00 [queued]>
[2024-06-04 13:00:17,898] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-06-04 13:00:17,898] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-06-04 13:00:17,898] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-06-04 13:00:17,909] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): transform_dataset_task> on 2024-06-03 00:00:00+00:00
[2024-06-04 13:00:17,914] {standard_task_runner.py:52} INFO - Started process 16443 to run task
[2024-06-04 13:00:17,917] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'transform_dataset_task', 'scheduled__2024-06-03T00:00:00+00:00', '--job-id', '177', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion.py', '--cfg-path', '/tmp/tmp9k0xxo4p', '--error-file', '/tmp/tmp0u1877q9']
[2024-06-04 13:00:17,922] {standard_task_runner.py:77} INFO - Job 177: Subtask transform_dataset_task
[2024-06-04 13:00:17,987] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcs_dag.transform_dataset_task scheduled__2024-06-03T00:00:00+00:00 [running]> on host 7ae6972dd88f
[2024-06-04 13:00:18,050] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcs_dag
AIRFLOW_CTX_TASK_ID=transform_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2024-06-03T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-06-03T00:00:00+00:00
[2024-06-04 13:00:18,085] {logging_mixin.py:109} INFO - <class 'pandas.core.frame.DataFrame'>
RangeIndex: 20 entries, 0 to 19
Data columns (total 4 columns):
 #   Column       Non-Null Count  Dtype 
---  ------       --------------  ----- 
 0   status       20 non-null     object
 1   copyright    20 non-null     object
 2   num_results  20 non-null     int64 
 3   results      20 non-null     object
dtypes: int64(1), object(3)
memory usage: 768.0+ bytes
[2024-06-04 13:00:18,085] {logging_mixin.py:109} INFO - None
[2024-06-04 13:00:18,085] {python.py:175} INFO - Done. Returned value was: None
[2024-06-04 13:00:18,095] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=transform_dataset_task, execution_date=20240603T000000, start_date=20240604T130017, end_date=20240604T130018
[2024-06-04 13:00:18,129] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-06-04 13:00:18,160] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-04 13:02:20,297] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcs_dag.transform_dataset_task scheduled__2024-06-03T00:00:00+00:00 [queued]>
[2024-06-04 13:02:20,307] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcs_dag.transform_dataset_task scheduled__2024-06-03T00:00:00+00:00 [queued]>
[2024-06-04 13:02:20,308] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-06-04 13:02:20,308] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2024-06-04 13:02:20,308] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-06-04 13:02:20,318] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): transform_dataset_task> on 2024-06-03 00:00:00+00:00
[2024-06-04 13:02:20,323] {standard_task_runner.py:52} INFO - Started process 16618 to run task
[2024-06-04 13:02:20,326] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'transform_dataset_task', 'scheduled__2024-06-03T00:00:00+00:00', '--job-id', '181', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion.py', '--cfg-path', '/tmp/tmp72tav2u0', '--error-file', '/tmp/tmpgh0yrjo3']
[2024-06-04 13:02:20,331] {standard_task_runner.py:77} INFO - Job 181: Subtask transform_dataset_task
[2024-06-04 13:02:20,384] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcs_dag.transform_dataset_task scheduled__2024-06-03T00:00:00+00:00 [running]> on host 7ae6972dd88f
[2024-06-04 13:02:20,435] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcs_dag
AIRFLOW_CTX_TASK_ID=transform_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2024-06-03T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-06-03T00:00:00+00:00
[2024-06-04 13:02:20,474] {logging_mixin.py:109} INFO - 0     {'uri': 'nyt://article/c707e1ce-cbe2-5853-8b0d...
1     {'uri': 'nyt://article/a7d007e0-6136-5fee-a79c...
2     {'uri': 'nyt://article/d8374226-4af8-5304-8a5d...
3     {'uri': 'nyt://article/5417a5b2-29a8-5e47-8795...
4     {'uri': 'nyt://article/2d5a07d8-4816-5279-bb6e...
5     {'uri': 'nyt://article/036ce54d-1a74-58b6-800c...
6     {'uri': 'nyt://article/031be2ac-5f2f-5e57-92ca...
7     {'uri': 'nyt://article/946429a3-e297-54be-bde0...
8     {'uri': 'nyt://article/361d20a8-556b-56ba-a9a6...
9     {'uri': 'nyt://article/12a6e758-2cd4-50b4-a7df...
10    {'uri': 'nyt://article/1c83957c-9fda-5c7d-9a7f...
11    {'uri': 'nyt://article/a3709974-3888-52a9-8bfb...
12    {'uri': 'nyt://article/2cbdb175-4b53-5943-a06c...
13    {'uri': 'nyt://interactive/91d165d6-83c8-523e-...
14    {'uri': 'nyt://interactive/1fbf720e-a531-510b-...
15    {'uri': 'nyt://interactive/3e859d5e-5e8b-5da2-...
16    {'uri': 'nyt://article/36a15f6e-41b0-565a-a096...
17    {'uri': 'nyt://article/d9a998fb-8914-5681-a6bf...
18    {'uri': 'nyt://article/ab9db728-d744-5a51-a220...
19    {'uri': 'nyt://article/12b3e832-294f-5e89-bcac...
Name: results, dtype: object
[2024-06-04 13:02:20,475] {python.py:175} INFO - Done. Returned value was: None
[2024-06-04 13:02:20,485] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=transform_dataset_task, execution_date=20240603T000000, start_date=20240604T130220, end_date=20240604T130220
[2024-06-04 13:02:20,538] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-06-04 13:02:20,571] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
